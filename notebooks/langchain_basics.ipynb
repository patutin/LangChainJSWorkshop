{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain JS Basics\n",
    "\n",
    "You can also run this notebook online [at Noteable.io](https://app.noteable.io/published/d9902d51-c5e9-4d89-bcb1-f82521ab4497/rag_fusion).\n",
    "\n",
    "  \n",
    ">\n",
    " LangChain is a framework for developing applications powered by language models.  \n",
    "\n",
    "\n",
    "  \n",
    "You can use npm, yarn, or pnpm to install LangChain.js.  \n",
    " `npm install -S langchain` or `yarn add langchain` or `pnpm add langchain`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "Using LangChain will usually require integrations with one or more model providers, data stores, APIs, etc. For this example, we'll use OpenAI's model APIs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "// npm install langchain\n",
    "\n",
    "// export OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE\n",
    "\n",
    "import { OpenAI } from \"npm:langchain/llms/openai\";\n",
    "\n",
    "const openAi = new OpenAI({})\n",
    "\n",
    "// or pass the key in directly via the openAIApiKey parameter when initializing the OpenAI LLM class\n",
    "\n",
    "//\n",
    "//const openAiwithParameters = new OpenAI({\n",
    "//    openAIApiKey: \"YOUR_KEY_HERE\",\n",
    "//});\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First call to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const response = await openAi.call(`Say hello!`);\n",
    "\n",
    "console.log(response);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model I/O\n",
    "The core element of any language model application is...the model. LangChain gives you the building blocks to interface with any language model.\n",
    "\n",
    "**Prompts**: Templatize, dynamically select, and manage model inputs   \n",
    "**Language models**: Make calls to language models through common interfaces   \n",
    "**Output parsers**: Extract information from model outputs  \n",
    "\n",
    "## Prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { PromptTemplate } from \"npm:langchain/prompts\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const prompt = PromptTemplate.fromTemplate(\n",
    "    `You are a naming consultant for new companies.\n",
    "     What is a good name for a company that makes {product}?`\n",
    ");\n",
    "  \n",
    "const formattedPrompt = await prompt.format({product: \"colorful socks\"});\n",
    "\n",
    "console.log(formattedPrompt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "const response = await openAi.call(formattedPrompt);\n",
    "\n",
    "console.log(response);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create template with no input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const noInputPrompt = new PromptTemplate({\n",
    "    inputVariables: [],\n",
    "    template: \"Tell me a joke.\",\n",
    "  });\n",
    "  const formattedNoInputPrompt = await noInputPrompt.format();\n",
    "  \n",
    "  console.log(formattedNoInputPrompt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create template with input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const multipleInputPrompt = new PromptTemplate({\n",
    "    inputVariables: [\"adjective\", \"content\"],\n",
    "    template: \"Tell me a {adjective} joke about {content}.\",\n",
    "  });\n",
    "  const formattedMultipleInputPrompt = await multipleInputPrompt.format({\n",
    "    adjective: \"funny\",\n",
    "    content: \"chickens\",\n",
    "  });\n",
    "  \n",
    "  console.log(formattedMultipleInputPrompt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import {\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "  } from \"npm:langchain/prompts\";\n",
    "\n",
    "  import {\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    "  } from \"npm:langchain/schema\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const systemTemplate =\n",
    "  \"You are a helpful assistant that translates {input_language} to {output_language}.\";\n",
    "const humanTemplate = \"{text}\";\n",
    "\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", systemTemplate],\n",
    "  [\"human\", humanTemplate],\n",
    "]);\n",
    "\n",
    "// Format the messages\n",
    "const formattedChatPrompt = await chatPrompt.formatMessages({\n",
    "  input_language: \"English\",\n",
    "  output_language: \"French\",\n",
    "  text: \"I love programming.\",\n",
    "});\n",
    "\n",
    "console.log(formattedChatPrompt); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { PromptTemplate, PipelinePromptTemplate } from \"npm:langchain/prompts\";\n",
    "\n",
    "const fullPrompt = PromptTemplate.fromTemplate(`{introduction}\n",
    "\n",
    "{example}\n",
    "\n",
    "{start}`);\n",
    "\n",
    "const introductionPrompt = PromptTemplate.fromTemplate(\n",
    "  `You are impersonating {person}.`\n",
    ");\n",
    "\n",
    "const examplePrompt =\n",
    "  PromptTemplate.fromTemplate(`Here's an example of an interaction:\n",
    "Q: {example_q}\n",
    "A: {example_a}`);\n",
    "\n",
    "const startPrompt = PromptTemplate.fromTemplate(`Now, do this for real!\n",
    "Q: {input}\n",
    "A:`);\n",
    "\n",
    "const composedPrompt = new PipelinePromptTemplate({\n",
    "  pipelinePrompts: [\n",
    "    {\n",
    "      name: \"introduction\",\n",
    "      prompt: introductionPrompt,\n",
    "    },\n",
    "    {\n",
    "      name: \"example\",\n",
    "      prompt: examplePrompt,\n",
    "    },\n",
    "    {\n",
    "      name: \"start\",\n",
    "      prompt: startPrompt,\n",
    "    },\n",
    "  ],\n",
    "  finalPrompt: fullPrompt,\n",
    "});\n",
    "\n",
    "const formattedPrompt = await composedPrompt.format({\n",
    "  person: \"Elon Musk\",\n",
    "  example_q: `What's your favorite car?`,\n",
    "  example_a: \"Telsa\",\n",
    "  input: `What's your favorite social media site?`,\n",
    "});\n",
    "\n",
    "console.log(formattedPrompt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language models\n",
    "LangChain provides interfaces and integrations for two types of models:  \n",
    "\n",
    "- LLMs: Models that take a text string as input and return a text string  \n",
    "- Chat models: Models that are backed by a language model but take a list of Chat Messages as input and return a Chat Message  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const model = new OpenAI({\n",
    "})\n",
    "\n",
    "const prompt = PromptTemplate.fromTemplate(\n",
    "    `You are a naming consultant for new companies.\n",
    "     What is a good name for a company that makes {product}?`\n",
    ");\n",
    "  \n",
    "const formattedPrompt = await prompt.format({product: \"animal food\"});\n",
    "\n",
    "const response = await model.call(formattedPrompt);\n",
    "\n",
    "console.log(response);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI Model Parametres. Full List you can find at [Langchain Docs](https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const model = new OpenAI({\n",
    "    modelName: \"text-davinci-003\",\n",
    "    temperature: 0.7,\n",
    "    cache: false,\n",
    "})\n",
    "\n",
    "const prompt = PromptTemplate.fromTemplate(\n",
    "    `You are a naming consultant for new companies.\n",
    "     What is a good name for a company that makes {product}?`\n",
    ");\n",
    "  \n",
    "const formattedPrompt = await prompt.format({product: \"animal food\"});\n",
    "\n",
    "const response = await model.call(formattedPrompt);\n",
    "\n",
    "console.log(response);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model interace unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pedigree Gift Use myW-20380 when registering reserve has succeeded cord buget zero concept\n"
     ]
    }
   ],
   "source": [
    "import { PromptTemplate } from \"npm:langchain/prompts\";\n",
    "import { HfInference } from 'npm:@huggingface/inference';\n",
    "import { HuggingFaceInference } from \"npm:langchain/llms/hf\";\n",
    "\n",
    "const model = new HuggingFaceInference({\n",
    "    model: \"google/flan-t5-xxl\",\n",
    "    temperature: 1.7,\n",
    "    cache: false,\n",
    "})\n",
    "\n",
    "const prompt = PromptTemplate.fromTemplate(\n",
    "    `You are a naming consultant for new companies.\n",
    "     What is a good name for a company that makes {product}?`\n",
    ");\n",
    "  \n",
    "const formattedPrompt = await prompt.format({product: \"animal food1\"});\n",
    "\n",
    "const response = await model.call(formattedPrompt);\n",
    "\n",
    "console.log(response);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output parsers\n",
    "\n",
    "String output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"npm:langchain/chat_models/openai\";\n",
    "import { StringOutputParser } from \"npm:langchain/schema/output_parser\";\n",
    "\n",
    "const parser = new StringOutputParser();\n",
    "\n",
    "const model = new ChatOpenAI({ temperature: 0 });\n",
    "\n",
    "const stream = await model.pipe(parser).stream(\"Hello there!\");\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "  console.log(chunk);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structured output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { OpenAI } from \"npm:langchain/llms/openai\";\n",
    "import { PromptTemplate } from \"npm:langchain/prompts\";\n",
    "import { StructuredOutputParser } from \"npm:langchain/output_parsers\";\n",
    "import { RunnableSequence } from \"npm:langchain/schema/runnable\";\n",
    "\n",
    "const parser = StructuredOutputParser.fromNamesAndDescriptions({\n",
    "  answer: \"answer to the user's question\",\n",
    "  source: \"source used to answer the user's question, should be a website.\",\n",
    "});\n",
    "\n",
    "const chain = RunnableSequence.from([\n",
    "  PromptTemplate.fromTemplate(\n",
    "    \"Answer the users question as best as possible.\\n{format_instructions}\\n{question}\"\n",
    "  ),\n",
    "  new OpenAI({ temperature: 0 }),\n",
    "  parser,\n",
    "]);\n",
    "\n",
    "const response = await chain.invoke({\n",
    "  question: \"What is the capital of France?\",\n",
    "  format_instructions: parser.getFormatInstructions(),\n",
    "});\n",
    "\n",
    "console.log(response);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
